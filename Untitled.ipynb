{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from settings import s, e\n",
    "\n",
    "\n",
    "\n",
    "choices = ['RIGHT', 'LEFT', 'UP', 'DOWN', 'BOMB', 'WAIT']\n",
    "\n",
    "\n",
    "def setup(agent):\n",
    "    K.clear_session()\n",
    "    \n",
    "    D = len(choices)\n",
    "    \n",
    "    #========================\n",
    "    #  Define Model\n",
    "    #========================\n",
    "    \n",
    "    inputs = Input(shape=(1,))\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    pred = Dense(D, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=pred)\n",
    "    #model.compile(loss=\"hinge\", optimizer=\"adam\")\n",
    "\n",
    "    agent.model = model\n",
    "\n",
    "    \n",
    "    #========================\n",
    "    #  Define Training Update\n",
    "    #========================\n",
    "\n",
    "    action_holder = Input(shape=(1,), dtype='int32')  # in j=0,...,D-1\n",
    "    reward_holder = Input(shape=(1,))\n",
    "    \n",
    "    # applies a mask to the outputs so that only the prediction for the chosen action is considered\n",
    "    responsible_weight = tf.reduce_sum(tf.boolean_mask(pred, tf.one_hot(action_holder, D)[:,0,:]))\n",
    "\n",
    "    loss = - (tf.log(responsible_weight) * reward_holder)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(0.1)\n",
    "    update = optimizer.minimize(loss)\n",
    "    \n",
    "    \n",
    "    # Initialize all variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    K.get_session().run(init_op)\n",
    "\n",
    "    # the alternative Keras way:\n",
    "    #training_model = Model(inputs=[inputs, action_holder, reward_holder], outputs=loss)\n",
    "    #training_model.compile(loss=lambda y_true, y_pred: y_pred, optimizer='Adam')\n",
    "\n",
    "    \n",
    "    agent.update = update\n",
    "    \n",
    "    agent.inputs = inputs\n",
    "    agent.action_holder = action_holder\n",
    "    agent.reward_holder = reward_holder\n",
    "    \n",
    "\n",
    "    np.random.seed()\n",
    "\n",
    "def act(agent):\n",
    "    # agent.game_state\n",
    "    print('Pick action at random')\n",
    "\n",
    "    #agent.next_action = np.random.choice(choices, p=[.23, .23, .23, .23, .08, .00])\n",
    "\n",
    "    pred = agent.model.predict(np.array([1]))\n",
    "    agent.next_action = choices[np.argmax(pred)]\n",
    "    print(agent.next_action)\n",
    "\n",
    "def reward_update(agent):\n",
    "    print('Update')\n",
    "    # agent.events\n",
    "    pass\n",
    "\n",
    "def end_of_episode(agent):\n",
    "    #model = agent.model\n",
    "    #model.train_on_batch(x, y, class_weight=None)\n",
    "    \n",
    "    sess = K.get_session()\n",
    "    sess.run([agent.update], feed_dict={agent.inputs: [[1]], agent.reward_holder:[[2]],agent.action_holder:[[5]]})\n",
    "    print('End of Episode')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick action at random\n",
      "BOMB\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "setup(agent)\n",
    "\n",
    "act(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Episode\n"
     ]
    }
   ],
   "source": [
    "end_of_episode(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'step' The number of steps in the episode so far, starting at 1.\n",
    "\n",
    "'arena' A 2D numpy array describing the tiles of the game board. Its entries are 1 for\n",
    "crates, −1 for stone walls and 0 for free tiles.\n",
    "\n",
    "'self' A tuple (x, y, n, b) describing your own agent. x and y are its coordinates on\n",
    "the board, n its name and b ∈ {0, 1} a \u001d",
    "ag indicating if the 'BOMB' action is\n",
    "possible (i.e. no own bomb is currently ticking).\n",
    "\n",
    "'others' A list of tuples like the one above for all opponents that are still in the game.\n",
    "\n",
    "'bombs' A list of tuples (x, y, t) of coordinates and countdowns for all active bombs.\n",
    "\n",
    "'explosions' A 2D numpy array stating, for each tile, for how many steps an explosion will\n",
    "be present. Where there is no explosion, the value is 0.\n",
    "\n",
    "'coins' A list of coordinates (x, y) for all currently collectable coins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(game_state):\n",
    "    arena = game_state['arena']\n",
    "    self = game_state['self']\n",
    "    others = game_state['others']\n",
    "    bombs = game_state['bombs']\n",
    "    explosions = game_state['explosions']\n",
    "    coins = game_state['coins']\n",
    "    # channels: arena, self, others (3), bombs, explosions, coins -> c = 8\n",
    "    c = 8\n",
    "    X = np.zeros((s.cols, s.rows, c))\n",
    "    \n",
    "    X[:,:,0] = arena\n",
    "    \n",
    "    X[self[0],self[1],1] = self[3]\n",
    "    \n",
    "    for i in range(len(others)):\n",
    "        X[others[i][0], others[i][1], i+2] = others[i][3]\n",
    "    \n",
    "    for i in range(len(bombs)):\n",
    "        X[bombs[i][0], bombs[i][1], 5] = bombs[i][2]\n",
    "    \n",
    "    X[:,:,6] = explosions\n",
    "    \n",
    "    for i in range(len(coins)):\n",
    "        X[coins[i][0], coins[i][1], 7] = 1\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
