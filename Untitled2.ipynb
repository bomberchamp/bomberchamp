{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from settings import s, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['arena', 'coins', 'agents', 'actions', 'permutations', 'times', 'n_steps'])\n",
      "[0.007486043491429984, 0.00851680018419137, 0.006612038020021427, 0.0024573372470008004]\n"
     ]
    }
   ],
   "source": [
    "replay_file = 'Replay 2019-03-01 13-29-57'\n",
    "\n",
    "with open(f'replays/simple_agent/{replay_file}.pt', 'rb') as f:\n",
    "    replay = pickle.load(f)\n",
    "\n",
    "print(replay.keys())\n",
    "print(replay['times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple import play_replay\n",
    "\n",
    "X, Y = play_replay(replay)\n",
    "X = np.stack(X)\n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['arena', 'coins', 'agents', 'actions', 'permutations', 'times', 'n_steps'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay['n_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(844, 17, 17, 6)\n",
      "2\n",
      "(1688, 17, 17, 6)\n",
      "3\n",
      "(2532, 17, 17, 6)\n",
      "4\n",
      "(3376, 17, 17, 6)\n",
      "5\n",
      "(4220, 17, 17, 6)\n",
      "6\n",
      "(5064, 17, 17, 6)\n",
      "7\n",
      "(5908, 17, 17, 6)\n",
      "8\n",
      "(6752, 17, 17, 6)\n",
      "9\n",
      "(7596, 17, 17, 6)\n",
      "10\n",
      "(8440, 17, 17, 6)\n",
      "11\n",
      "(9284, 17, 17, 6)\n",
      "12\n",
      "(10128, 17, 17, 6)\n",
      "13\n",
      "(10972, 17, 17, 6)\n",
      "14\n",
      "(11816, 17, 17, 6)\n",
      "15\n",
      "(12660, 17, 17, 6)\n",
      "16\n",
      "(13504, 17, 17, 6)\n",
      "17\n",
      "(14348, 17, 17, 6)\n",
      "18\n",
      "(15192, 17, 17, 6)\n",
      "19\n",
      "(16036, 17, 17, 6)\n",
      "20\n",
      "(16880, 17, 17, 6)\n",
      "21\n",
      "(17724, 17, 17, 6)\n",
      "22\n",
      "(18568, 17, 17, 6)\n",
      "23\n",
      "(19412, 17, 17, 6)\n",
      "24\n",
      "(20256, 17, 17, 6)\n",
      "25\n",
      "(21100, 17, 17, 6)\n",
      "26\n",
      "(21944, 17, 17, 6)\n",
      "27\n",
      "(22788, 17, 17, 6)\n",
      "28\n",
      "(23632, 17, 17, 6)\n",
      "29\n",
      "(24476, 17, 17, 6)\n",
      "30\n",
      "(25320, 17, 17, 6)\n",
      "31\n",
      "(26164, 17, 17, 6)\n",
      "32\n",
      "(27008, 17, 17, 6)\n",
      "33\n",
      "(27852, 17, 17, 6)\n",
      "34\n",
      "(28696, 17, 17, 6)\n",
      "35\n",
      "(29540, 17, 17, 6)\n",
      "36\n",
      "(30384, 17, 17, 6)\n",
      "37\n",
      "(31228, 17, 17, 6)\n",
      "38\n",
      "(32072, 17, 17, 6)\n",
      "39\n",
      "(32916, 17, 17, 6)\n",
      "40\n",
      "(33760, 17, 17, 6)\n",
      "41\n",
      "(34604, 17, 17, 6)\n",
      "42\n",
      "(35448, 17, 17, 6)\n",
      "43\n",
      "(36292, 17, 17, 6)\n",
      "44\n",
      "(37136, 17, 17, 6)\n",
      "45\n",
      "(37980, 17, 17, 6)\n",
      "46\n",
      "(38824, 17, 17, 6)\n",
      "47\n",
      "(39668, 17, 17, 6)\n",
      "48\n",
      "(40512, 17, 17, 6)\n",
      "49\n",
      "(41356, 17, 17, 6)\n",
      "50\n",
      "(42200, 17, 17, 6)\n",
      "51\n",
      "(43044, 17, 17, 6)\n",
      "52\n",
      "(43888, 17, 17, 6)\n",
      "53\n",
      "(44732, 17, 17, 6)\n",
      "54\n",
      "(45576, 17, 17, 6)\n",
      "55\n",
      "(46420, 17, 17, 6)\n",
      "56\n",
      "(47264, 17, 17, 6)\n",
      "57\n",
      "(48108, 17, 17, 6)\n",
      "58\n",
      "(48952, 17, 17, 6)\n",
      "59\n",
      "(49796, 17, 17, 6)\n",
      "60\n",
      "(50640, 17, 17, 6)\n",
      "61\n",
      "(51484, 17, 17, 6)\n",
      "62\n",
      "(52328, 17, 17, 6)\n",
      "63\n",
      "(53172, 17, 17, 6)\n",
      "64\n",
      "(54016, 17, 17, 6)\n",
      "65\n",
      "(54860, 17, 17, 6)\n",
      "66\n",
      "(55704, 17, 17, 6)\n",
      "67\n",
      "(56548, 17, 17, 6)\n",
      "68\n",
      "(57392, 17, 17, 6)\n",
      "69\n",
      "(58236, 17, 17, 6)\n",
      "70\n",
      "(59080, 17, 17, 6)\n",
      "71\n",
      "(59924, 17, 17, 6)\n",
      "72\n",
      "(60768, 17, 17, 6)\n",
      "73\n",
      "(61612, 17, 17, 6)\n",
      "74\n",
      "(62456, 17, 17, 6)\n",
      "75\n",
      "(63300, 17, 17, 6)\n",
      "76\n",
      "(64144, 17, 17, 6)\n",
      "77\n",
      "(64988, 17, 17, 6)\n",
      "78\n",
      "(65832, 17, 17, 6)\n",
      "79\n",
      "(66676, 17, 17, 6)\n",
      "80\n",
      "(67520, 17, 17, 6)\n",
      "81\n",
      "(68364, 17, 17, 6)\n",
      "82\n",
      "(69208, 17, 17, 6)\n",
      "83\n",
      "(70052, 17, 17, 6)\n",
      "84\n",
      "(70896, 17, 17, 6)\n",
      "85\n",
      "(71740, 17, 17, 6)\n",
      "86\n",
      "(72584, 17, 17, 6)\n",
      "87\n",
      "(73428, 17, 17, 6)\n",
      "88\n",
      "(74272, 17, 17, 6)\n",
      "89\n",
      "(75116, 17, 17, 6)\n",
      "90\n",
      "(75960, 17, 17, 6)\n",
      "91\n",
      "(76804, 17, 17, 6)\n",
      "92\n",
      "(77648, 17, 17, 6)\n",
      "93\n",
      "(78492, 17, 17, 6)\n",
      "94\n",
      "(79336, 17, 17, 6)\n",
      "95\n",
      "(80180, 17, 17, 6)\n",
      "96\n",
      "(81024, 17, 17, 6)\n",
      "97\n",
      "(81868, 17, 17, 6)\n",
      "98\n",
      "(82712, 17, 17, 6)\n",
      "99\n",
      "(83556, 17, 17, 6)\n",
      "100\n",
      "(84400, 17, 17, 6)\n",
      "101\n",
      "(85244, 17, 17, 6)\n",
      "102\n",
      "(86088, 17, 17, 6)\n",
      "103\n",
      "(86932, 17, 17, 6)\n",
      "104\n",
      "(87776, 17, 17, 6)\n",
      "105\n",
      "(88620, 17, 17, 6)\n",
      "106\n",
      "(89464, 17, 17, 6)\n",
      "107\n",
      "(90308, 17, 17, 6)\n",
      "108\n",
      "(91152, 17, 17, 6)\n",
      "109\n",
      "(91996, 17, 17, 6)\n",
      "110\n",
      "(92840, 17, 17, 6)\n",
      "111\n",
      "(93684, 17, 17, 6)\n",
      "112\n",
      "(94528, 17, 17, 6)\n",
      "113\n",
      "(95372, 17, 17, 6)\n",
      "114\n",
      "(96216, 17, 17, 6)\n",
      "115\n",
      "(97060, 17, 17, 6)\n",
      "116\n",
      "(97904, 17, 17, 6)\n",
      "117\n",
      "(98748, 17, 17, 6)\n",
      "118\n",
      "(99592, 17, 17, 6)\n",
      "119\n",
      "(100436, 17, 17, 6)\n",
      "120\n",
      "(101280, 17, 17, 6)\n",
      "121\n",
      "(102124, 17, 17, 6)\n",
      "122\n",
      "(102968, 17, 17, 6)\n",
      "123\n",
      "(103812, 17, 17, 6)\n",
      "124\n",
      "(104656, 17, 17, 6)\n",
      "125\n",
      "(105500, 17, 17, 6)\n",
      "126\n",
      "(106344, 17, 17, 6)\n",
      "127\n",
      "(107188, 17, 17, 6)\n",
      "128\n",
      "(108032, 17, 17, 6)\n",
      "129\n",
      "(108876, 17, 17, 6)\n",
      "130\n",
      "(109720, 17, 17, 6)\n",
      "131\n",
      "(110564, 17, 17, 6)\n",
      "132\n",
      "(111408, 17, 17, 6)\n",
      "133\n",
      "(112252, 17, 17, 6)\n",
      "134\n",
      "(113096, 17, 17, 6)\n",
      "135\n",
      "(113940, 17, 17, 6)\n",
      "136\n",
      "(114784, 17, 17, 6)\n",
      "137\n",
      "(115628, 17, 17, 6)\n",
      "138\n",
      "(116472, 17, 17, 6)\n",
      "139\n",
      "(117316, 17, 17, 6)\n",
      "140\n",
      "(118160, 17, 17, 6)\n",
      "141\n",
      "(119004, 17, 17, 6)\n",
      "142\n",
      "(119848, 17, 17, 6)\n",
      "143\n",
      "(120692, 17, 17, 6)\n",
      "144\n",
      "(121536, 17, 17, 6)\n",
      "145\n",
      "(122380, 17, 17, 6)\n",
      "146\n",
      "(123224, 17, 17, 6)\n",
      "147\n",
      "(124068, 17, 17, 6)\n",
      "148\n",
      "(124912, 17, 17, 6)\n",
      "149\n",
      "(125756, 17, 17, 6)\n",
      "150\n",
      "(126600, 17, 17, 6)\n",
      "151\n",
      "(127444, 17, 17, 6)\n",
      "152\n",
      "(128288, 17, 17, 6)\n",
      "153\n",
      "(129132, 17, 17, 6)\n",
      "154\n",
      "(129976, 17, 17, 6)\n",
      "155\n",
      "(130820, 17, 17, 6)\n",
      "156\n",
      "(131664, 17, 17, 6)\n",
      "157\n",
      "(132508, 17, 17, 6)\n",
      "158\n",
      "(133352, 17, 17, 6)\n",
      "159\n",
      "(134196, 17, 17, 6)\n",
      "160\n",
      "(135040, 17, 17, 6)\n",
      "161\n",
      "(135884, 17, 17, 6)\n",
      "162\n",
      "(136728, 17, 17, 6)\n",
      "163\n",
      "(137572, 17, 17, 6)\n",
      "164\n",
      "(138416, 17, 17, 6)\n",
      "165\n",
      "(139260, 17, 17, 6)\n",
      "166\n",
      "(140104, 17, 17, 6)\n",
      "167\n",
      "(140948, 17, 17, 6)\n",
      "168\n",
      "(141792, 17, 17, 6)\n",
      "169\n",
      "(142636, 17, 17, 6)\n",
      "170\n",
      "(143480, 17, 17, 6)\n",
      "171\n",
      "(144324, 17, 17, 6)\n",
      "172\n",
      "(145168, 17, 17, 6)\n",
      "173\n",
      "(146012, 17, 17, 6)\n",
      "174\n",
      "(146856, 17, 17, 6)\n",
      "175\n",
      "(147700, 17, 17, 6)\n",
      "176\n",
      "(148544, 17, 17, 6)\n",
      "177\n",
      "(149388, 17, 17, 6)\n",
      "178\n",
      "(150232, 17, 17, 6)\n",
      "179\n",
      "(151076, 17, 17, 6)\n",
      "180\n",
      "(151920, 17, 17, 6)\n",
      "181\n",
      "(152764, 17, 17, 6)\n",
      "182\n",
      "(153608, 17, 17, 6)\n",
      "183\n",
      "(154452, 17, 17, 6)\n",
      "184\n",
      "(155296, 17, 17, 6)\n",
      "185\n",
      "(156140, 17, 17, 6)\n",
      "186\n",
      "(156984, 17, 17, 6)\n",
      "187\n",
      "(157828, 17, 17, 6)\n",
      "188\n",
      "(158672, 17, 17, 6)\n",
      "189\n",
      "(159516, 17, 17, 6)\n",
      "190\n",
      "(160360, 17, 17, 6)\n",
      "191\n",
      "(161204, 17, 17, 6)\n",
      "192\n",
      "(162048, 17, 17, 6)\n",
      "193\n",
      "(162892, 17, 17, 6)\n",
      "194\n",
      "(163736, 17, 17, 6)\n",
      "195\n",
      "(164580, 17, 17, 6)\n",
      "196\n",
      "(165424, 17, 17, 6)\n",
      "197\n",
      "(166268, 17, 17, 6)\n",
      "198\n",
      "(167112, 17, 17, 6)\n",
      "199\n",
      "(167956, 17, 17, 6)\n",
      "200\n",
      "(168800, 17, 17, 6)\n",
      "201\n",
      "(169644, 17, 17, 6)\n",
      "202\n",
      "(170488, 17, 17, 6)\n",
      "203\n",
      "(171332, 17, 17, 6)\n",
      "204\n",
      "(172176, 17, 17, 6)\n",
      "205\n",
      "(173020, 17, 17, 6)\n",
      "206\n",
      "(173864, 17, 17, 6)\n",
      "207\n",
      "(174708, 17, 17, 6)\n",
      "208\n",
      "(175552, 17, 17, 6)\n",
      "209\n",
      "(176396, 17, 17, 6)\n",
      "210\n",
      "(177240, 17, 17, 6)\n",
      "211\n",
      "(178084, 17, 17, 6)\n",
      "212\n",
      "(178928, 17, 17, 6)\n",
      "213\n",
      "(179772, 17, 17, 6)\n",
      "214\n",
      "(180616, 17, 17, 6)\n",
      "215\n",
      "(181460, 17, 17, 6)\n",
      "216\n",
      "(182304, 17, 17, 6)\n",
      "217\n",
      "(183148, 17, 17, 6)\n",
      "218\n",
      "(183992, 17, 17, 6)\n",
      "219\n",
      "(184836, 17, 17, 6)\n",
      "220\n",
      "(185680, 17, 17, 6)\n",
      "221\n",
      "(186524, 17, 17, 6)\n",
      "222\n",
      "(187368, 17, 17, 6)\n",
      "223\n",
      "(188212, 17, 17, 6)\n",
      "224\n",
      "(189056, 17, 17, 6)\n",
      "225\n",
      "(189900, 17, 17, 6)\n",
      "226\n",
      "(190744, 17, 17, 6)\n",
      "227\n",
      "(191588, 17, 17, 6)\n",
      "228\n",
      "(192432, 17, 17, 6)\n",
      "229\n",
      "(193276, 17, 17, 6)\n",
      "230\n",
      "(194120, 17, 17, 6)\n",
      "231\n",
      "(194964, 17, 17, 6)\n",
      "232\n",
      "(195808, 17, 17, 6)\n",
      "233\n",
      "(196652, 17, 17, 6)\n",
      "234\n",
      "(197496, 17, 17, 6)\n",
      "235\n",
      "(198340, 17, 17, 6)\n",
      "236\n",
      "(199184, 17, 17, 6)\n",
      "237\n",
      "(200028, 17, 17, 6)\n",
      "238\n",
      "(200872, 17, 17, 6)\n",
      "239\n",
      "(201716, 17, 17, 6)\n",
      "240\n",
      "(202560, 17, 17, 6)\n",
      "241\n",
      "(203404, 17, 17, 6)\n",
      "242\n",
      "(204248, 17, 17, 6)\n",
      "243\n",
      "(205092, 17, 17, 6)\n",
      "244\n",
      "(205936, 17, 17, 6)\n",
      "245\n",
      "(206780, 17, 17, 6)\n",
      "246\n",
      "(207624, 17, 17, 6)\n",
      "247\n",
      "(208468, 17, 17, 6)\n",
      "248\n",
      "(209312, 17, 17, 6)\n",
      "249\n",
      "(210156, 17, 17, 6)\n",
      "250\n",
      "(211000, 17, 17, 6)\n",
      "251\n",
      "(211844, 17, 17, 6)\n",
      "252\n",
      "(212688, 17, 17, 6)\n",
      "253\n",
      "(213532, 17, 17, 6)\n",
      "254\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-775d972473d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from simple import play_replay\n",
    "\n",
    "files = list(filter(lambda x: x.find('Replay', 0, 7) == 0, listdir('replays/simple_agent')))\n",
    "\n",
    "X = None\n",
    "Y = None\n",
    "\n",
    "i = 0\n",
    "for f in files:\n",
    "    i += 1\n",
    "    print(i)\n",
    "    with open(f'replays/simple_agent/{replay_file}.pt', 'rb') as f:\n",
    "        replay = pickle.load(f)\n",
    "    \n",
    "    X_, Y_ = play_replay(replay)\n",
    "    X_ = np.stack(X_)\n",
    "    Y_ = np.stack(Y_)\n",
    "    if X is None:\n",
    "        X = X_\n",
    "        Y = Y_\n",
    "    else:\n",
    "        X = np.concatenate((X, X_))\n",
    "        Y = np.concatenate((Y, Y_))\n",
    "        \n",
    "    print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213532,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( {\"X\": X, \"Y\": Y}, open( \"train_beginning.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-75d59d79091a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"train.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
     ]
    }
   ],
   "source": [
    "data = pickle.load( open( \"train.p\", \"rb\" ) )\n",
    "X = data['X']\n",
    "Y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "while True:\n",
    "    packet = s.recv(4096)\n",
    "    if not packet: break\n",
    "    data.append(packet)\n",
    "data_arr = pickle.loads(b\"\".join(data))\n",
    "print (data_arr)\n",
    "s.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "choices = ['RIGHT', 'LEFT', 'UP', 'DOWN', 'BOMB', 'WAIT']\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "D = len(choices)\n",
    "\n",
    "#========================\n",
    "#  Define Model\n",
    "#========================\n",
    "    \n",
    "inputs = Input(shape=(s.cols, s.rows, 6))\n",
    "x = Conv2D(8, 3, activation='relu', padding=\"same\")(inputs)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(16, 3, activation='relu', padding=\"same\")(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(32, 3, activation='relu', padding=\"same\")(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(32, 3, activation='relu', padding=\"same\")(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(32, 3, activation='relu', padding=\"same\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding=\"same\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "pred = Dense(D, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=pred)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200000/200000 [==============================] - 35s 173us/sample - loss: 0.2033\n",
      "Epoch 2/100\n",
      "200000/200000 [==============================] - 38s 191us/sample - loss: 0.1862\n",
      "Epoch 3/100\n",
      "200000/200000 [==============================] - 37s 186us/sample - loss: 0.1620\n",
      "Epoch 4/100\n",
      "200000/200000 [==============================] - 40s 201us/sample - loss: 0.1545\n",
      "Epoch 5/100\n",
      "200000/200000 [==============================] - 39s 196us/sample - loss: 0.1501\n",
      "Epoch 6/100\n",
      "200000/200000 [==============================] - 34s 171us/sample - loss: 0.1470\n",
      "Epoch 7/100\n",
      "200000/200000 [==============================] - 41s 204us/sample - loss: 0.1432\n",
      "Epoch 8/100\n",
      "200000/200000 [==============================] - 36s 179us/sample - loss: 0.1401\n",
      "Epoch 9/100\n",
      "200000/200000 [==============================] - 34s 172us/sample - loss: 0.1422\n",
      "Epoch 10/100\n",
      "200000/200000 [==============================] - 37s 184us/sample - loss: 0.1389\n",
      "Epoch 11/100\n",
      "200000/200000 [==============================] - 37s 185us/sample - loss: 0.1361\n",
      "Epoch 12/100\n",
      "200000/200000 [==============================] - 32s 158us/sample - loss: 0.1364\n",
      "Epoch 13/100\n",
      "200000/200000 [==============================] - 33s 163us/sample - loss: 0.1360\n",
      "Epoch 14/100\n",
      "200000/200000 [==============================] - 32s 160us/sample - loss: 0.1342\n",
      "Epoch 15/100\n",
      "200000/200000 [==============================] - 29s 143us/sample - loss: 0.1361\n",
      "Epoch 16/100\n",
      "200000/200000 [==============================] - 33s 165us/sample - loss: 0.1335\n",
      "Epoch 17/100\n",
      "200000/200000 [==============================] - 25s 125us/sample - loss: 0.1355\n",
      "Epoch 18/100\n",
      "200000/200000 [==============================] - 31s 154us/sample - loss: 0.1341\n",
      "Epoch 19/100\n",
      "200000/200000 [==============================] - 37s 183us/sample - loss: 0.1340\n",
      "Epoch 20/100\n",
      "200000/200000 [==============================] - 32s 161us/sample - loss: 0.1323\n",
      "Epoch 21/100\n",
      "200000/200000 [==============================] - 36s 178us/sample - loss: 0.1323\n",
      "Epoch 22/100\n",
      "200000/200000 [==============================] - 31s 157us/sample - loss: 0.1308\n",
      "Epoch 23/100\n",
      "200000/200000 [==============================] - 32s 161us/sample - loss: 0.1262\n",
      "Epoch 24/100\n",
      "200000/200000 [==============================] - 28s 140us/sample - loss: 0.1142\n",
      "Epoch 25/100\n",
      "200000/200000 [==============================] - 34s 171us/sample - loss: 0.1137\n",
      "Epoch 26/100\n",
      "200000/200000 [==============================] - 31s 156us/sample - loss: 0.1122\n",
      "Epoch 27/100\n",
      "200000/200000 [==============================] - 32s 159us/sample - loss: 0.1141\n",
      "Epoch 28/100\n",
      "200000/200000 [==============================] - 31s 156us/sample - loss: 0.1131\n",
      "Epoch 29/100\n",
      "200000/200000 [==============================] - 30s 152us/sample - loss: 0.1128\n",
      "Epoch 30/100\n",
      "200000/200000 [==============================] - 31s 157us/sample - loss: 0.1090\n",
      "Epoch 31/100\n",
      "200000/200000 [==============================] - 30s 150us/sample - loss: 0.1066\n",
      "Epoch 32/100\n",
      "200000/200000 [==============================] - 28s 141us/sample - loss: 0.1090\n",
      "Epoch 33/100\n",
      "200000/200000 [==============================] - 29s 146us/sample - loss: 0.1073\n",
      "Epoch 34/100\n",
      "200000/200000 [==============================] - 30s 152us/sample - loss: 0.0964\n",
      "Epoch 35/100\n",
      "200000/200000 [==============================] - 30s 152us/sample - loss: 0.0942\n",
      "Epoch 36/100\n",
      "200000/200000 [==============================] - 27s 133us/sample - loss: 0.0941\n",
      "Epoch 37/100\n",
      "200000/200000 [==============================] - 30s 151us/sample - loss: 0.0942\n",
      "Epoch 38/100\n",
      "200000/200000 [==============================] - 31s 155us/sample - loss: 0.0934\n",
      "Epoch 39/100\n",
      "200000/200000 [==============================] - 32s 161us/sample - loss: 0.0936\n",
      "Epoch 40/100\n",
      "200000/200000 [==============================] - 30s 152us/sample - loss: 0.0940\n",
      "Epoch 41/100\n",
      "200000/200000 [==============================] - 29s 145us/sample - loss: 0.0937\n",
      "Epoch 42/100\n",
      "200000/200000 [==============================] - 33s 166us/sample - loss: 0.0936\n",
      "Epoch 43/100\n",
      "200000/200000 [==============================] - 29s 143us/sample - loss: 0.0924\n",
      "Epoch 44/100\n",
      "200000/200000 [==============================] - 28s 141us/sample - loss: 0.0915\n",
      "Epoch 45/100\n",
      "200000/200000 [==============================] - 30s 150us/sample - loss: 0.0900\n",
      "Epoch 46/100\n",
      "200000/200000 [==============================] - 31s 156us/sample - loss: 0.0907\n",
      "Epoch 47/100\n",
      "200000/200000 [==============================] - 29s 145us/sample - loss: 0.0921\n",
      "Epoch 48/100\n",
      "200000/200000 [==============================] - 27s 133us/sample - loss: 0.0908\n",
      "Epoch 49/100\n",
      "200000/200000 [==============================] - 30s 150us/sample - loss: 0.0911\n",
      "Epoch 50/100\n",
      "200000/200000 [==============================] - 27s 134us/sample - loss: 0.0907\n",
      "Epoch 51/100\n",
      "200000/200000 [==============================] - 31s 154us/sample - loss: 0.0914\n",
      "Epoch 52/100\n",
      "200000/200000 [==============================] - 27s 135us/sample - loss: 0.0911\n",
      "Epoch 53/100\n",
      "200000/200000 [==============================] - 29s 147us/sample - loss: 0.0903\n",
      "Epoch 54/100\n",
      "200000/200000 [==============================] - 31s 154us/sample - loss: 0.0913\n",
      "Epoch 55/100\n",
      "200000/200000 [==============================] - 29s 145us/sample - loss: 0.0910\n",
      "Epoch 56/100\n",
      "200000/200000 [==============================] - 27s 135us/sample - loss: 0.0888\n",
      "Epoch 57/100\n",
      "200000/200000 [==============================] - 30s 149us/sample - loss: 0.0901\n",
      "Epoch 58/100\n",
      "200000/200000 [==============================] - 29s 143us/sample - loss: 0.0902\n",
      "Epoch 59/100\n",
      "200000/200000 [==============================] - 28s 140us/sample - loss: 0.0910\n",
      "Epoch 60/100\n",
      "200000/200000 [==============================] - 25s 125us/sample - loss: 0.0903\n",
      "Epoch 61/100\n",
      "200000/200000 [==============================] - 27s 135us/sample - loss: 0.0909\n",
      "Epoch 62/100\n",
      "200000/200000 [==============================] - 28s 138us/sample - loss: 0.0908\n",
      "Epoch 63/100\n",
      "200000/200000 [==============================] - 25s 126us/sample - loss: 0.0902\n",
      "Epoch 64/100\n",
      "200000/200000 [==============================] - 28s 139us/sample - loss: 0.0897\n",
      "Epoch 65/100\n",
      "200000/200000 [==============================] - 24s 122us/sample - loss: 0.0914\n",
      "Epoch 66/100\n",
      "200000/200000 [==============================] - 27s 135us/sample - loss: 0.0911\n",
      "Epoch 67/100\n",
      "200000/200000 [==============================] - 27s 133us/sample - loss: 0.0908\n",
      "Epoch 68/100\n",
      "200000/200000 [==============================] - 29s 146us/sample - loss: 0.0909\n",
      "Epoch 69/100\n",
      "200000/200000 [==============================] - 24s 122us/sample - loss: 0.0904\n",
      "Epoch 70/100\n",
      "200000/200000 [==============================] - 28s 140us/sample - loss: 0.0915\n",
      "Epoch 71/100\n",
      "200000/200000 [==============================] - 27s 137us/sample - loss: 0.0900\n",
      "Epoch 72/100\n",
      "200000/200000 [==============================] - 26s 128us/sample - loss: 0.0885\n",
      "Epoch 73/100\n",
      "200000/200000 [==============================] - 25s 124us/sample - loss: 0.0888\n",
      "Epoch 74/100\n",
      "200000/200000 [==============================] - 23s 115us/sample - loss: 0.0895\n",
      "Epoch 75/100\n",
      "200000/200000 [==============================] - 25s 125us/sample - loss: 0.0886\n",
      "Epoch 76/100\n",
      "200000/200000 [==============================] - 25s 127us/sample - loss: 0.0897\n",
      "Epoch 77/100\n",
      "200000/200000 [==============================] - 23s 116us/sample - loss: 0.0892\n",
      "Epoch 78/100\n",
      "200000/200000 [==============================] - 25s 125us/sample - loss: 0.0884\n",
      "Epoch 79/100\n",
      "200000/200000 [==============================] - 24s 122us/sample - loss: 0.0908\n",
      "Epoch 80/100\n",
      "200000/200000 [==============================] - 26s 132us/sample - loss: 0.0889\n",
      "Epoch 81/100\n",
      "200000/200000 [==============================] - 24s 121us/sample - loss: 0.0884\n",
      "Epoch 82/100\n",
      "200000/200000 [==============================] - 27s 133us/sample - loss: 0.0888\n",
      "Epoch 83/100\n",
      "200000/200000 [==============================] - 25s 127us/sample - loss: 0.0884\n",
      "Epoch 84/100\n",
      "200000/200000 [==============================] - 23s 114us/sample - loss: 0.0897\n",
      "Epoch 85/100\n",
      "200000/200000 [==============================] - 25s 124us/sample - loss: 0.0886\n",
      "Epoch 86/100\n",
      "200000/200000 [==============================] - 25s 125us/sample - loss: 0.0887\n",
      "Epoch 87/100\n",
      "200000/200000 [==============================] - 24s 120us/sample - loss: 0.0891\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 39s 195us/sample - loss: 0.0877\n",
      "Epoch 89/100\n",
      "200000/200000 [==============================] - 38s 191us/sample - loss: 0.0896\n",
      "Epoch 90/100\n",
      "200000/200000 [==============================] - 42s 209us/sample - loss: 0.0882\n",
      "Epoch 91/100\n",
      "200000/200000 [==============================] - 38s 188us/sample - loss: 0.0875\n",
      "Epoch 92/100\n",
      "200000/200000 [==============================] - 43s 213us/sample - loss: 0.0872\n",
      "Epoch 93/100\n",
      "200000/200000 [==============================] - 42s 209us/sample - loss: 0.0886\n",
      "Epoch 94/100\n",
      "200000/200000 [==============================] - 31s 157us/sample - loss: 0.0882\n",
      "Epoch 95/100\n",
      "200000/200000 [==============================] - 40s 202us/sample - loss: 0.0874\n",
      "Epoch 96/100\n",
      "200000/200000 [==============================] - 40s 201us/sample - loss: 0.0886\n",
      "Epoch 97/100\n",
      "200000/200000 [==============================] - 36s 178us/sample - loss: 0.0890\n",
      "Epoch 98/100\n",
      "200000/200000 [==============================] - 42s 212us/sample - loss: 0.0883\n",
      "Epoch 99/100\n",
      "200000/200000 [==============================] - 41s 204us/sample - loss: 0.0888\n",
      "Epoch 100/100\n",
      "200000/200000 [==============================] - 39s 193us/sample - loss: 0.0890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a90f624a8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = X.shape[0]\n",
    "N_train = 200000\n",
    "N_test = N - N_train\n",
    "perm = np.random.permutation(N)\n",
    "train = perm[:N_train]\n",
    "b = np.zeros((N_train, D))\n",
    "b[np.arange(N_train), Y[train]] = 1\n",
    "\n",
    "model.fit(X[train], b, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13532/13532 [==============================] - 1s 52us/sample - loss: 0.0651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06514656583787094"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = perm[N_train:]\n",
    "b = np.zeros((N_test, D))\n",
    "b[np.arange(N_test), Y[test]] = 1\n",
    "\n",
    "model.evaluate(X[test], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
