{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import s, e\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "\n",
    "from IPython.display import HTML, clear_output, display, update_display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from simple import Game\n",
    "\n",
    "from agent_code.tensor_agent.agent import TensorAgent\n",
    "from agent_code.tensor_agent.hyperparameters import hp\n",
    "from agent_code.tensor_agent.X import RelativeX2 as game_state_X\n",
    "from agent_code.tensor_agent.model import FullModel\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.buffer_size = 100\n",
    "hp.target_network_period = 10\n",
    "hp.epsilon = 0.\n",
    "hp.learning_rate=0.001\n",
    "hp.discount_factor=0.99\n",
    "hp.peaceful = False\n",
    "\n",
    "crate_density = 0.5\n",
    "aux_reward_crates = 0.2\n",
    "\n",
    "hurry_up = 1 * (1 - hp.discount_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = ['RIGHT', 'LEFT', 'UP', 'DOWN', 'BOMB', 'WAIT']\n",
    "action_y_map = {choices[i]: i for i in range(len(choices))}\n",
    "D = len(choices)\n",
    "\n",
    "K.clear_session()\n",
    "model = FullModel(game_state_X.shape, D)\n",
    "\n",
    "tensor_agent = TensorAgent(game_state_X.shape, D, weights=None, model=model) # alt: weights='tensor_agent-model.h5'\n",
    "\n",
    "agents = {\n",
    "    'tensor_agent': tensor_agent,\n",
    "    'tensor_agent-copy1': tensor_agent.clone(),\n",
    "    'tensor_agent-copy2': tensor_agent.clone(),\n",
    "    'tensor_agent-copy3': tensor_agent.clone()\n",
    "}\n",
    "train = {a: False for a in agents}\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.target.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_valid_actions(x, y, b, game):\n",
    "    # choices = ['RIGHT', 'LEFT', 'UP', 'DOWN', 'BOMB', 'WAIT']\n",
    "    valid = np.ones((6))\n",
    "    if not game.tile_is_free(x, y-1):\n",
    "        valid[2] = 0 # UP invalid\n",
    "    if not game.tile_is_free(x, y+1):\n",
    "        valid[3] = 0 # DOWN invalid\n",
    "    if not game.tile_is_free(x-1, y):\n",
    "        valid[1] = 0 # LEFT invalid\n",
    "    if not game.tile_is_free(x+1, y):\n",
    "        valid[0] = 0 # RIGHT invalid\n",
    "    if b<1:\n",
    "        valid[4] = 0\n",
    "\n",
    "    #valid[4] = 0\n",
    "    #valid[5] = 0\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step: 3200/2000000 Trained: 775 Moving Reward: 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = display(f'Starting...', display_id='progress')\n",
    "\n",
    "n_steps = 2000000\n",
    "game = None\n",
    "\n",
    "train = {n: True for n in agents.keys() }\n",
    "#train['tensor_agent'] = True\n",
    "\n",
    "moving_reward = 0\n",
    "episode_count = 0\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if game is None:\n",
    "        episode_count += 1\n",
    "        game = Game(*Game.create_arena(agents.keys(), crate_density=crate_density), aux_reward_crates=aux_reward_crates)\n",
    "\n",
    "    actions = {}\n",
    "    Xs = {}\n",
    "    for agent in game.agents:\n",
    "        x, y, name, b, _ = agent\n",
    "        \n",
    "        game_state = game.get_game_state(agent)\n",
    "        Xs[name] = game_state_X.get(game_state)\n",
    "        valid_actions = get_valid_actions(x, y, b, game)\n",
    "        actions[name] = agents[name].act(Xs[name], train=train[name], valid_actions=valid_actions)\n",
    "    \n",
    "    actions_as_string = {n: choices[actions[n]] for n in actions.keys()}\n",
    "    rewards = game.step(actions_as_string)\n",
    "    moving_reward = 0.99 * moving_reward + rewards['tensor_agent']\n",
    "    \n",
    "    for _, _, name, _, _ in game.agents:\n",
    "        if train[name]:\n",
    "            agents[name].reward_update([Xs[name], actions[name], rewards[name]-hurry_up])\n",
    "    \n",
    "    d.update(f'Episode {episode_count} Step: {step+1}/{n_steps} Trained: {model.steps} Moving Reward: {moving_reward:.2f}')\n",
    "    \n",
    "    if game.terminated:\n",
    "        for name, a in agents.items():\n",
    "            a.end_of_episode(save='tensor_agent-model.h5') # alt: save=None\n",
    "        \n",
    "        game = None\n",
    "\n",
    "d.update(f'Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = display(f'Starting...', display_id='progress_test')\n",
    "\n",
    "n_steps = 1000\n",
    "game = None\n",
    "\n",
    "train = {n: False for n in agents.keys()}\n",
    "moving_reward = 0\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if game is None:\n",
    "        game = Game(*Game.create_arena(agents.keys(), crate_density=0.75), aux_reward_crates=aux_reward_crates)\n",
    "\n",
    "    actions = {}\n",
    "    Xs = {}\n",
    "    img = np.zeros((17, 17, 3))\n",
    "    \n",
    "    for agent in game.agents:\n",
    "        x, y, name, b, _ = agent\n",
    "        \n",
    "        game_state = game.get_game_state(agent)\n",
    "        img[:,:,0] = (game_state['arena'] == -1) * 0.75\n",
    "        img[:,:,0] += game_state['arena'] == 1\n",
    "        coins = game_state['coins']\n",
    "        for i in range(len(coins)):\n",
    "            img[coins[i][0], coins[i][1], 1] = 0.75\n",
    "        img[x,y,1] = 1\n",
    "        img[:,:,2] = game_state['explosions'] / np.max(game_state['explosions'])\n",
    "        bombs = game_state['bombs']\n",
    "        \n",
    "        for i in range(len(bombs)):\n",
    "            img[bombs[i][0], bombs[i][1], 2] = 0.75 - bombs[i][2] / (s.bomb_timer) / 2\n",
    "        \n",
    "        Xs[name] = game_state_X.get(game_state)\n",
    "        valid_actions = get_valid_actions(x, y, b, game)\n",
    "        actions[name] = agents[name].act(Xs[name], train=train[name], valid_actions=valid_actions)\n",
    "    \n",
    "    imgs.append(img)\n",
    "    \n",
    "    actions_as_string = {n: choices[actions[n]] for n in actions.keys()}\n",
    "    print(actions_as_string)\n",
    "    rewards = game.step(actions_as_string)\n",
    "    moving_reward = moving_reward + rewards['tensor_agent']\n",
    "    \n",
    "    d.update(f'Step: {step+1}/{n_steps} Moving Reward: {moving_reward:.2f}')\n",
    "    \n",
    "    if game.terminated:\n",
    "        #for name, a in agents.items():\n",
    "            #a.end_of_episode(save='tensor_agent-model.h5') # alt: save=None\n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def animation(imgs, interval=50):\n",
    "    import matplotlib.animation\n",
    "    \n",
    "    steps = len(imgs)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(t):\n",
    "        plt.imshow(imgs[t])\n",
    "\n",
    "    ani = matplotlib.animation.FuncAnimation(fig, animate, frames=steps, interval=interval)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anim = animation(imgs[:20], interval=300)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "! rm anim/*\n",
    "for i in range(len(imgs)):\n",
    "    Image.fromarray(np.uint8(imgs[i]*255)).resize((17*10,17*10)).save('anim/{:0>3d}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! convert anim/*.png movie.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
